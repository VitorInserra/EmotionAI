{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af866962",
   "metadata": {},
   "source": [
    "# Stamp Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "from ML.model_training import (\n",
    "    train_lstm,\n",
    "    build_decod_lstm_sequences,\n",
    ")\n",
    "from ML import utils\n",
    "import sys\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "# Data prep functions\n",
    "def load_eego_df(\n",
    "    filename: str | Path = \"EEGo_labeled.csv\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load EEGo_labeled.csv and do minimal cleaning.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Sort by (user, session, time)\n",
    "    sort_cols = [\"user_id\", \"session_id\"]\n",
    "    if \"time_elapsed\" in df.columns:\n",
    "        sort_cols.append(\"time_elapsed\")\n",
    "    elif \"timestamp\" in df.columns:\n",
    "        sort_cols.append(\"timestamp\")\n",
    "\n",
    "    df = df.sort_values(sort_cols).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def select_eego_features(df: pd.DataFrame) -> list[str]:\n",
    "    eeg_prefixes = [\n",
    "        \"AF3_\", \"F7_\", \"F3_\", \"FC5_\", \"T7_\", \"P7_\",\n",
    "        \"O1_\", \"O2_\", \"P8_\", \"T8_\", \"FC6_\", \"F4_\", \"F8_\", \"AF4_\",\n",
    "    ]\n",
    "    \n",
    "    eeg_features = [\n",
    "        c\n",
    "        for c in df.columns\n",
    "        if any(c.startswith(p) for p in eeg_prefixes)\n",
    "    ]\n",
    "\n",
    "    feature_cols = eeg_features\n",
    "    return feature_cols\n",
    "\n",
    "def balance_binary_sequences(\n",
    "    X: np.ndarray, y: np.ndarray, seed: int = 5\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Downsample the majority class at the *sequence* level\n",
    "    so that classes 0 and 1 are balanced.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    idx_pos = np.where(y == 1.0)[0]\n",
    "    idx_neg = np.where(y == 0.0)[0]\n",
    "\n",
    "    n_pos = len(idx_pos)\n",
    "    n_neg = len(idx_neg)\n",
    "\n",
    "    if n_pos == 0 or n_neg == 0 or n_pos == n_neg:\n",
    "        return X, y\n",
    "\n",
    "    if n_pos > n_neg:\n",
    "        keep_pos = rng.choice(idx_pos, size=n_neg, replace=False)\n",
    "        keep_idx = np.concatenate([keep_pos, idx_neg])\n",
    "    else:\n",
    "        keep_neg = rng.choice(idx_neg, size=n_pos, replace=False)\n",
    "        keep_idx = np.concatenate([keep_neg, idx_pos])\n",
    "\n",
    "    keep_idx = np.sort(keep_idx)\n",
    "    return X[keep_idx], y[keep_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f120520",
   "metadata": {},
   "source": [
    "Setup the DECOD dataset with features and identify and organize by end_stamps.\n",
    "Create a feature table using eegproc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_eego = load_eego_df(\"DECOD/DECOD.csv\")\n",
    "print(\"DECOD shape:\", df_eego.shape)\n",
    "\n",
    "TEXT_VERSION = \"text_version\"\n",
    "AROUSAL = \"arousal\"\n",
    "\n",
    "df_eego[AROUSAL] = np.nan\n",
    "\n",
    "df_eego.loc[df_eego[TEXT_VERSION] > 20, AROUSAL] = 1\n",
    "df_eego.loc[\n",
    "    (df_eego[TEXT_VERSION] > 10) & (df_eego[TEXT_VERSION] <= 20),\n",
    "    AROUSAL\n",
    "] = 0\n",
    "\n",
    "df_eego = df_eego[df_eego[AROUSAL].isin([0, 1])].copy()\n",
    "print(\"Binary df shape:\", df_eego.shape)\n",
    "counts = df_eego[AROUSAL].value_counts()\n",
    "\n",
    "print(counts)\n",
    "print(counts[1]/(counts[1]+counts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eegproc as eeg\n",
    "\n",
    "features_table: pd.DataFrame = pd.DataFrame()\n",
    "freqs = {\n",
    "    # \"delta\": (0.5, 4.0),\n",
    "    \"theta\": (4.0, 8.0),\n",
    "    \"alpha\": (8.0, 13.0),\n",
    "    \"betaL\": (13.0, 20.0),\n",
    "    \"betaH\": (20.0, 30.0),\n",
    "    \"gamma\": (30.0, 45.0),\n",
    "}\n",
    "ch_names = [\n",
    "    \"AF3\",\n",
    "    \"F7\",\n",
    "    \"F3\",\n",
    "    \"FC5\",\n",
    "    \"T7\",\n",
    "    \"P7\",\n",
    "    \"O1\",\n",
    "    \"O2\",\n",
    "    \"P8\",\n",
    "    \"T8\",\n",
    "    \"FC6\",\n",
    "    \"F4\",\n",
    "    \"F8\",\n",
    "    \"AF4\",\n",
    "]\n",
    "meta_cols = [\n",
    "    \"user_id\",\n",
    "    \"session_id\",\n",
    "    \"start_stamp\",\n",
    "    \"end_stamp\",\n",
    "    \"eye_id\",\n",
    "    \"text_version\",\n",
    "    \"seen_words\",\n",
    "    \"arousal\",\n",
    "    \"valence\",\n",
    "    \"sensor_contact_quality\",\n",
    "    \"timestamp\",\n",
    "]\n",
    "\n",
    "FS = 128\n",
    "\n",
    "# --- only keep sessions WITHOUT text_version in [15, 16] ---\n",
    "EXCLUDED_TEXT_VERSIONS = [16]\n",
    "\n",
    "valid_sessions = [\n",
    "    sid\n",
    "    for sid, g in df_eego.groupby(\"session_id\")\n",
    "    if not g[\"text_version\"].isin(EXCLUDED_TEXT_VERSIONS).any()\n",
    "]\n",
    "\n",
    "print(\"Number of valid sessions (excluding text_version 15/16):\", len(valid_sessions))\n",
    "print(valid_sessions)\n",
    "\n",
    "for session in valid_sessions:\n",
    "    mask = df_eego[\"session_id\"] == session\n",
    "    eeg_df = df_eego.loc[mask, :].copy()\n",
    "\n",
    "    if eeg_df.empty:\n",
    "        continue\n",
    "\n",
    "    session_id = eeg_df[\"session_id\"]\n",
    "    end_stamp = eeg_df[\"end_stamp\"]\n",
    "    arousal = eeg_df[AROUSAL]\n",
    "\n",
    "    eeg_df = eeg_df.drop(\n",
    "        columns=meta_cols,\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "\n",
    "    shannons = eeg.shannons_entropy(eeg_df, bands=freqs)\n",
    "    da = utils.compute_asymmetry_from_psd(eeg_df)\n",
    "\n",
    "    batch = pd.concat([session_id, end_stamp, arousal, eeg_df, shannons, da], axis=1)\n",
    "\n",
    "    features_table = pd.concat([features_table, batch], ignore_index=True)\n",
    "\n",
    "features_table = features_table.sort_values(\n",
    "    by=[\"session_id\", \"end_stamp\"],\n",
    "    ascending=True\n",
    ")\n",
    "features_table.to_csv(\"datasets/decod_features.csv\", index=False)\n",
    "features_table = pd.read_csv(\"datasets/decod_features.csv\")\n",
    "\n",
    "feature_cols = select_eego_features(features_table)\n",
    "print(\"n_features:\", len(feature_cols))\n",
    "print(feature_cols)\n",
    "\n",
    "session_ids = features_table[\"session_id\"].unique().tolist()\n",
    "print(\"Number of sessions:\", len(session_ids))\n",
    "print(session_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c4a678",
   "metadata": {},
   "source": [
    "## LSTM LOO Optimizer\n",
    "\n",
    "Performs Leave-One-Out (omit one session) cross-validation, where each **session_id**\n",
    "is held-out as the test fold once. We search over a small hyperparameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefdec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 0.5\n",
    "param_grid = {\n",
    "    \"lr\": [0.0001],\n",
    "    \"epochs\": [30],\n",
    "    \"units\": [512],\n",
    "    \"batch_size\": [64],\n",
    "    \"patience\": [50],\n",
    "}\n",
    "\n",
    "NUM_RUNS = 5\n",
    "HELD_OUT_PER_RUN = 8\n",
    "\n",
    "end_stamps = list(features_table[\"end_stamp\"].unique())\n",
    "\n",
    "stamps = []\n",
    "while len(stamps) < NUM_RUNS:\n",
    "    res = random.sample(end_stamps, HELD_OUT_PER_RUN)\n",
    "    stamps.append(res)\n",
    "\n",
    "print(\"Stamp sets (held out per run):\")\n",
    "for i, s in enumerate(stamps, 1):\n",
    "    print(f\"Run {i}: {len(s)} stamps\")\n",
    "\n",
    "best_params = None\n",
    "best_mean_acc = -np.inf\n",
    "cm_full = [[0, 0], [0, 0]]\n",
    "\n",
    "print(\"Starting EEGo LOO hyperparameter search over sessions...\\n\")\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "for lr, epochs, units, batch_size, patience in product(\n",
    "    param_grid[\"lr\"],\n",
    "    param_grid[\"epochs\"],\n",
    "    param_grid[\"units\"],\n",
    "    param_grid[\"batch_size\"],\n",
    "    param_grid[\"patience\"],\n",
    "):\n",
    "    combo_accs = []\n",
    "\n",
    "    for stamp_list in stamps:\n",
    "        print(\"LEFT OUT (stamps):\", stamp_list)\n",
    "\n",
    "        mask_test = features_table[\"end_stamp\"].isin(stamp_list)\n",
    "        train_df = features_table[~mask_test].reset_index(drop=True)\n",
    "        test_df = features_table[mask_test].reset_index(drop=True)\n",
    "\n",
    "        print(train_df[AROUSAL].value_counts())\n",
    "        print(test_df[AROUSAL].value_counts())\n",
    "        X_train_seq, y_train_seq = build_decod_lstm_sequences(\n",
    "            train_df,\n",
    "            feature_cols=feature_cols,\n",
    "            target_col=AROUSAL,\n",
    "            group_by=\"end_stamp\",\n",
    "            thresh=THRESH,\n",
    "            fixed_T=125,\n",
    "        )\n",
    "        X_test_seq, y_test_seq = build_decod_lstm_sequences(\n",
    "            test_df,\n",
    "            feature_cols=feature_cols,\n",
    "            target_col=AROUSAL,\n",
    "            group_by=\"end_stamp\",\n",
    "            thresh=THRESH,\n",
    "            fixed_T=125,\n",
    "        )\n",
    "\n",
    "        # X_train_seq, y_train_seq = balance_binary_sequences(X_train_seq, y_train_seq)\n",
    "        # X_test_seq, y_test_seq = balance_binary_sequences(X_test_seq, y_test_seq)\n",
    "        print(X_train_seq.shape)\n",
    "        print(X_test_seq.shape)\n",
    "        lstm_model, X_test_eval, y_test_eval = train_lstm(\n",
    "            X_train_seq,\n",
    "            X_test_seq,\n",
    "            y_train_seq,\n",
    "            y_test_seq,\n",
    "            lr=lr,\n",
    "            epochs=epochs,\n",
    "            units=units,\n",
    "            batch_size=batch_size,\n",
    "            patience=patience,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        y_pred_prob = lstm_model.predict(X_test_eval).ravel()\n",
    "        y_pred = (y_pred_prob >= 0.5).astype(\"int32\")\n",
    "        y_true = y_test_eval.astype(\"int32\")\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "        cm_full += cm\n",
    "\n",
    "        print(acc)\n",
    "        print(cm)\n",
    "        combo_accs.append(acc)\n",
    "\n",
    "    mean_acc = float(np.mean(combo_accs))\n",
    "    std_acc = float(np.std(combo_accs))\n",
    "\n",
    "    print(\n",
    "        f\"lr={lr}, epochs={epochs}, units={units}, batch={batch_size}, \"\n",
    "        f\" -> mean acc={mean_acc:.4f} (std={std_acc:.4f})\"\n",
    "    )\n",
    "\n",
    "    if mean_acc > best_mean_acc:\n",
    "        best_mean_acc = mean_acc\n",
    "        best_params = {\n",
    "            \"lr\": lr,\n",
    "            \"epochs\": epochs,\n",
    "            \"units\": units,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"patience\": patience,\n",
    "        }\n",
    "\n",
    "print(\"\\nBest DECOD LOO mean test accuracy:\", f\"{best_mean_acc:.4f}\")\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Aggregated confusion matrix from your LOO runs\n",
    "# Rows = true labels, Columns = predicted labels\n",
    "# [[TN, FP],\n",
    "#  [FN, TP]]\n",
    "print(cm_full)\n",
    "\n",
    "class_names = [\"Low (0)\", \"High (1)\"]\n",
    "\n",
    "# --- Plot confusion matrix ---\n",
    "fig, ax = plt.subplots(figsize=(4, 4), dpi=300)  # high-res for publication\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_full,\n",
    "                              display_labels=class_names)\n",
    "\n",
    "disp.plot(values_format=\"d\", ax=ax, colorbar=False)\n",
    "\n",
    "ax.set_xlabel(\"Predicted label\", fontsize=10)\n",
    "ax.set_ylabel(\"True label\", fontsize=10)\n",
    "ax.set_title(\"BiLSTM Arousal Decoder Batch-Grouping\\n(LOO CV)\", fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Compute and print basic metrics ---\n",
    "tn, fp, fn, tp = cm_full.ravel()\n",
    "\n",
    "accuracy = (tp + tn) / cm_full.sum()\n",
    "precision_1 = tp / (tp + fp) if (tp + fp) > 0 else float(\"nan\")\n",
    "recall_1 = tp / (tp + fn) if (tp + fn) > 0 else float(\"nan\")\n",
    "f1_1 = (2 * precision_1 * recall_1 / (precision_1 + recall_1)\n",
    "        if precision_1 + recall_1 > 0 else float(\"nan\"))\n",
    "\n",
    "print(f\"Confusion matrix:\\n{cm_full}\")\n",
    "print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "print(f\"Precision (class 1): {precision_1:.3f}\")\n",
    "print(f\"Recall (class 1):    {recall_1:.3f}\")\n",
    "print(f\"F1-score (class 1):  {f1_1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
